{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret.json','r') as fp:\n",
    "    a=json.load(fp)\n",
    "#    print(a)\n",
    "#Twitter API credentials\n",
    "    consumer_key = a['consumer_key']\n",
    "    consumer_secret = a['consumer_secret']\n",
    "    access_key = a['access_token']\n",
    "    access_secret = a['access_token_secret']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(keyword,filename):\n",
    "    #search for tweet with \n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []    \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    #new_tweets = api.user_timeline(screen_name = screen_name,count=10)\n",
    "    new_tweets = api.search_tweets(keyword,count = 1)\n",
    "    \n",
    "    print(new_tweets[0]._json['text'])\n",
    "#    json.dump(new_tweets[0]._json,sys.stdout,indent=4)\n",
    "    \n",
    "#    json.dump(new_tweets[0]._json,sys.stdout,indent=4)\n",
    "    return 0\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "#    while len(new_tweets) > 0:\n",
    "    while False:\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        #new_tweets = api.user_timeline(screen_name = screen_name,count=10,max_id=oldest)\n",
    "        new_tweets = api.search_tweets(screen_name)\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        if(len(alltweets) > 300):\n",
    "            break\n",
    "        print( \"...%s tweets downloaded so far\" % (len(alltweets)) )\n",
    "       \n",
    "    #write tweet objects to JSON\n",
    "    file = open(filename, 'w') \n",
    "    print( \"Writing tweet objects to JSON please wait...\")\n",
    "    file.write('[\\n')\n",
    "    for status in alltweets:\n",
    "        json.dump(status._json,file,sort_keys = True,indent = 4)\n",
    "        file.write(',\\n')\n",
    "    #    json.dumps(status._json,indent=4)\n",
    "    #close the file\n",
    "    file.write('{}\\n]')\n",
    "    print( \"Done\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-890f11e1684d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#pass in the username of the account you want to download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mget_all_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"boston\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_all_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"boston\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_some_tweet(filename):\n",
    "    fp = open(filename,'r')\n",
    "    tweets_from_file=json.load(fp)\n",
    "    a = json.dumps(tweets_from_file,indent=4)\n",
    "    file.close()\n",
    "    return tweets_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tweet objects to JSON please wait...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#file=open('tweet-boston.json','r')\n",
    "filename = 'tweet-boston.json'\n",
    "tweet_text_keyword = 'boston'\n",
    "search_tweets(tweet_text_keyword,filename)\n",
    "tweet_list = show_some_tweet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surpreendido por tudo a Deus toda Glória por vosso amor, apoio e dedicação livro Família dádiva de Deus… https://t.co/flbGRUzw3L\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'tweet-boston.json'\n",
    "tweet_text_keyword = 'boston'\n",
    "search_tweets(tweet_text_keyword,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
